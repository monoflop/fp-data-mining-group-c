{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "outname = 'trans1.csv'\n",
    "outdir = './data/transformed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_strip(data: pd.DataFrame, outdir: str, outname: str):\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "\n",
    "    fullname = os.path.join(outdir, outname)    \n",
    "\n",
    "    data.to_csv(fullname)\n",
    "\n",
    "def load_strip(path: str)-> pd.DataFrame: \n",
    "    return pd.read_csv(path, sep=',')\n",
    "\n",
    "def init_strip(strip: str)->pd.DataFrame:\n",
    "    #if not os.path.exists(outdir+outname):\n",
    "    print(\"Recreate transformed strip\")\n",
    "    strip = pd.read_csv(strip, sep=',')\n",
    "\n",
    "    \"\"\"print(strip.head(n=1))\n",
    "\n",
    "    print(strip['frame_number'].max())\n",
    "    print(strip['run_number'].max())\"\"\"\n",
    "    strip2 = strip.drop('strip_id',axis = 1)\\\n",
    "                    .drop('timestamp',axis = 1)\\\n",
    "                    .drop('vicon_x',axis = 1)\\\n",
    "                    .drop('vicon_y',axis = 1)\n",
    "    strip = strip2.groupby(['run_number','frame_number']).agg(pd.Series.tolist)\n",
    "    #save_strip(strip, outdir, outname)\n",
    "    strip.reset_index(inplace=True)\n",
    "    return strip\n",
    "    \"\"\"else:\n",
    "        print(\"Read transformed strip\")\n",
    "        strip = load_strip(outdir+outname)\n",
    "        #print(strip.head(n=100))\n",
    "        return strip\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recreate transformed strip\n",
      "Recreate transformed strip\n",
      "Recreate transformed strip\n",
      "Recreate transformed strip\n",
      "Recreate transformed strip\n"
     ]
    }
   ],
   "source": [
    "# Read data and goup it\n",
    "strips = [2,3,4,5]\n",
    "df_main = init_strip('data/train/strip_6_train.csv')\n",
    "for s in strips:\n",
    "    df_main.append(init_strip('data/train/strip_%i_train.csv' % s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [run_number, frame_number, node_id, ax, ay, az, gx, gy, gz, mx, my, mz, r, near]\n",
       "Index: []"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>run_number</th>\n      <th>frame_number</th>\n      <th>node_id</th>\n      <th>ax</th>\n      <th>ay</th>\n      <th>az</th>\n      <th>gx</th>\n      <th>gy</th>\n      <th>gz</th>\n      <th>mx</th>\n      <th>my</th>\n      <th>mz</th>\n      <th>r</th>\n      <th>near</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df_main.head(n=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_data(df: pd.DataFrame):\n",
    "    tmp = df[['run_number', 'frame_number', 'node_id']]\n",
    "    near = pd.DataFrame(df['near'].values.tolist()).mean(1)\n",
    "    for index, row in tmp.iterrows():\n",
    "        nodes = row['node_id']\n",
    "        length = 0\n",
    "        if isinstance(nodes, list): \n",
    "            length = len(nodes)\n",
    "        if length < 15:\n",
    "            run = row['run_number']\n",
    "            frame = row['frame_number']\n",
    "            print(\"Missing val in %i %i\" % (run, frame))\n",
    "            for i in range(1,16):\n",
    "                if i not in nodes:\n",
    "                    df.loc[-1] = [run, frame, i, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, near]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add missing rows to ds\n",
    "add_missing_data(df_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_strip(strip_3_4,'./', 'test_7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " #df_main = df_main.fillna(df_main.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format table to use it for classifier\n",
    "def split_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    columns = [\"ax\", \"ay\", \"az\", \"gx\", \"gy\", \"gz\", \"mx\", \"my\", \"mz\", \"r\"]\n",
    "    newColumns = range(1,16)\n",
    "    df2 = pd.DataFrame()\n",
    "    for c in columns:\n",
    "        cols = list(map(lambda x: c+str(x), newColumns))\n",
    "        new_df = pd.DataFrame(df[c].to_list(), columns=cols)\n",
    "        df2 = pd.concat([df2, new_df], axis=1)\n",
    "    # add near column \n",
    "    df2['near'] = pd.DataFrame(df['near'].values.tolist()).mean(1)\n",
    "    return df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_splittet = split_data(df_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(strip: pd.DataFrame):\n",
    "    X = strip.drop('near',axis = 1)\n",
    "    Y = strip['near']\n",
    "    X = X.fillna(X.mean())\n",
    "    return train_test_split(X, Y, test_size = 0.25, random_state = 42)\n",
    "def scale_data(data: list):\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(data[0])\n",
    "    sc.fit(data[1])\n",
    "    data[0] = sc.transform(data[0])\n",
    "    data[1] = sc.transform(data[1])\n",
    "def apply_forest(forest: RandomForestClassifier, train_data: list):\n",
    "    forest.fit(train_data[0], train_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_main = get_train_test_data(df_main_splittet) #X_train, X_test, Y_train, Y_test\n",
    "scale_data(train_data_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "forest = RandomForestClassifier(n_estimators=1000, random_state = 100)\n",
    "apply_forest(forest, train_data_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_prediction = forest.predict(train_data_main[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9445713045498453"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "#accuracy_score(Y_test, forest_prediction)\n",
    "roc_auc_score(train_data_main[3], forest_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_strip(forest_prediction, './', 'predictions.csv')"
   ]
  }
 ]
}